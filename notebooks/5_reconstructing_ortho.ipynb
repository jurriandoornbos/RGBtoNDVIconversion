{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f51d1db0-869d-4bf6-a000-e5110de8065b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\judoj\\documents\\programming\\uavgeo\\uavgeo\\compute\\products.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import uavgeo as ug\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "import ultralytics\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb5a82-e1dc-47c7-a267-e7965918a67a",
   "metadata": {},
   "source": [
    "# pix2pix result analysis\n",
    "\n",
    "1. Data loading and resetting to geographic coordinates using the test-splits\n",
    "2. Visualizing the correlation of epoch200 vs real (with density)\n",
    "3. Visualizing the epoch improvements\n",
    "4. Visualizing rgb-true-p2p_e200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bb5edae-bd4b-4ff9-8ce5-e0d06a671641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I just adjusted these everytim for all the runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f8f6960d-a711-420f-92ba-5c75e4c1a65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasplits \n",
    "cwd = os.getcwd()\n",
    "\n",
    "chips = gpd.read_file(\"../data/canyelles_chips_256.geojson\")\n",
    "\n",
    "# load the original orthomosaic \n",
    "ortho = rxr.open_rasterio(\"../data/canyelles/orthos/rgb_230609.tif\",mode = \"w\")\n",
    "\n",
    "#alignment (if required)\n",
    "r= rxr.open_rasterio(\"../data/canyelles/orthos/cropped_r_230609.tif\",mode = \"w\")\n",
    "ortho = ortho.rio.reproject_match(r).sel(band=[1,2,3])\n",
    "single_band  = r\n",
    "\n",
    "#split the ndvi raster to acquire the boundaries, xylims etc.\n",
    "test_rgbs = [single_band.rio.clip_box(minx = row.geometry.bounds[0], miny =row.geometry.bounds[1] ,maxx =row.geometry.bounds[2] , maxy= row.geometry.bounds[3]) for i, row in chips.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad44856d-fc78-4fe1-91f7-4f41ed9b80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def check_pattern_matches(pattern, string_list):\n",
    "    matched_strings = []\n",
    "    for string in string_list:\n",
    "        if re.search(pattern, string):\n",
    "            matched_strings.append(string)\n",
    "    return matched_strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb50899b-4533-47ac-9cfa-81464534e198",
   "metadata": {},
   "source": [
    "## 1. Reconstruct the P2P imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cafddcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reconstruct an epoch that has passed thorugh p2p\n",
    "folder = \"../data/generated_ndvi/canyelles_trgb_ndvi_256\"\n",
    "\n",
    "fakeb = \"fake_B\"\n",
    "realb = \"real_B\"\n",
    "reala = \"real_A\"\n",
    "\n",
    "        \n",
    "imgs = [os.path.join(img) for img in os.listdir(folder)]\n",
    "real_a =[os.path.join(folder, file) for file in check_pattern_matches(reala, imgs)]\n",
    "real_b = [os.path.join(folder, file) for file in check_pattern_matches(realb, imgs)]\n",
    "fake_b = [os.path.join(folder, file) for file in check_pattern_matches(fakeb, imgs)]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "831ce9cb-412f-47c0-859a-497485cf8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load them as images\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def image_to_numpy_array(image_path):\n",
    "    # Open the image using Pillow\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Convert the image to a NumPy array\n",
    "    numpy_array = np.array(image)\n",
    "\n",
    "    return numpy_array\n",
    "real_a_arr =[image_to_numpy_array(file) for file in real_a]\n",
    "real_b_arr = [image_to_numpy_array(file) for file in real_b]\n",
    "fake_b_arr = [image_to_numpy_array(file) for file in fake_b]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "339d50f8-bf2d-4216-bb67-05903ed8000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix dimension error due to jpg and png loading of the 512/p2pHD model\n",
    "#fake_b_arr = [arr.reshape((512,512,1)) for arr in fake_b_arr]\n",
    "#real_b_arr = [arr.reshape((512,512,1)) for arr in real_b_arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23e49e8c-afff-4b88-ad17-67eb97d102db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\judoj\\mambaforge\\envs\\ndvi\\Lib\\site-packages\\numpy\\core\\numeric.py:407: RuntimeWarning: invalid value encountered in cast\n",
      "  multiarray.copyto(res, fill_value, casting='unsafe')\n"
     ]
    }
   ],
   "source": [
    "# empty rgb array from ortho:\n",
    "\n",
    "empty_rgb = xr.full_like(ortho.sel(band=[1,2,3]).astype(np.uint8), fill_value=np.nan)\n",
    "empty_ndvi = xr.full_like(single_band, fill_value=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a515704-e189-401c-a095-fe417c8c1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_chip_to_rxr(darray, geom, crs):\n",
    "\n",
    "    min_x, min_y, max_x, max_y = geom.geometry.bounds\n",
    "    \n",
    "    x_coords = np.linspace(min_x, max_x, darray.shape[1])\n",
    "    y_coords =np.linspace(min_y, max_y, darray.shape[0])[::-1]\n",
    "    #darray = np.rot90(darray)\n",
    "    return xr.DataArray(darray, dims=(\"y\", \"x\", \"band\"), coords={\"x\": x_coords, \"y\": y_coords}).rio.write_crs(crs).transpose('band', 'y', 'x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af270f86-3e3f-4182-b2c7-b9159de7f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rioxarray import merge\n",
    "\n",
    "rgb_test_list = [np_chip_to_rxr(real_a_arr[i], row, chips.crs) for i, row in chips.iterrows()]\n",
    "#add the empty_rgb to the list\n",
    "rgb_test = merge.merge_arrays([empty_rgb] + rgb_test_list)\n",
    "\n",
    "# FOR NDVI\n",
    "ndvi_test_list = [np_chip_to_rxr(real_b_arr[i], row, chips.crs).sel(band=0) for i, row in chips.iterrows()]\n",
    "#add the empty_ndvi to the list\n",
    "ndvi_test = merge.merge_arrays([empty_ndvi] + ndvi_test_list)   \n",
    "\n",
    "# FOR P2P NDVI\n",
    "ndvi_p2p_list = [np_chip_to_rxr(fake_b_arr[i], row, chips.crs).sel(band=0) for i, row in chips.iterrows()]\n",
    "#add the empty_rgb to the list\n",
    "ndvi_p2p = merge.merge_arrays([empty_ndvi] + ndvi_p2p_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "686e5549-84a7-4e94-94c4-9e775c960ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRS.from_epsg(4326)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndvi_p2p.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ef9e765-f7ca-481b-94b4-e62d9bd8393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip to test-area to reduce array size\n",
    "test=chips\n",
    "\n",
    "ndvi_p2p = ndvi_p2p.rio.clip_box(minx = test.bounds.min().minx, miny =test.bounds.min().miny ,maxx =test.bounds.max().maxx , maxy= test.bounds.max().maxy) \n",
    "\n",
    "ndvi_test = ndvi_test.rio.clip_box(minx = test.bounds.min().minx, miny =test.bounds.min().miny ,maxx =test.bounds.max().maxx , maxy= test.bounds.max().maxy) \n",
    "\n",
    "rgb_test = rgb_test.rio.clip_box(minx = test.bounds.min().minx, miny =test.bounds.min().miny ,maxx =test.bounds.max().maxx , maxy= test.bounds.max().maxy) \n",
    "\n",
    "# Scale ndvi to -1 : 1 \n",
    "ndvi_p2p = ndvi_p2p.where(ndvi_p2p>0)\n",
    "ndvi_p2p = (ndvi_p2p/127.5)-1\n",
    "\n",
    "ndvi_test = ndvi_test.where(ndvi_test>0)\n",
    "ndvi_test = (ndvi_test/127.5)-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e721c0-82f1-4c20-8326-c550c6044c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# export for some visual inspection in qgis\n",
    "\n",
    "rgb_test.rio.to_raster(\"../data/orthos/reconstructed/canyelles_trgb.tif\")\n",
    "ndvi_test.rio.to_raster(\"../data/orthos/reconstructed/canyelles_ndvi_real.tif\")\n",
    "ndvi_p2p.rio.to_raster(\"../data/orthos/reconstructed/canyelles_ndvi_p2p.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8354635c-6bec-45a1-960d-ec776b3a8e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
