{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRm-USlsHgEV",
    "outputId": "16ac0781-3384-46be-d339-ba8da9a1f2d1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n",
      "remote: Enumerating objects: 2513, done.\u001b[K\n",
      "remote: Total 2513 (delta 0), reused 0 (delta 0), pack-reused 2513\u001b[K\n",
      "Receiving objects: 100% (2513/2513), 8.20 MiB | 12.58 MiB/s, done.\n",
      "Resolving deltas: 100% (1575/1575), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Pt3igws3eiVp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1EySlOXwwoa",
    "outputId": "e800524f-de71-432c-f748-a33812b9b328",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.16.0.dev20230705+cu118)\n",
      "Collecting dominate>=2.4.0 (from -r requirements.txt (line 3))\n",
      "  Downloading dominate-2.8.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting visdom>=0.1.8.8 (from -r requirements.txt (line 4))\n",
      "  Downloading visdom-0.2.4.tar.gz (1.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.15.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.0rc1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->-r requirements.txt (line 1)) (68.0.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->-r requirements.txt (line 1)) (0.40.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->-r requirements.txt (line 1)) (3.26.4)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->-r requirements.txt (line 1)) (16.0.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (1.24.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (2.28.1)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision>=0.5.0 (from -r requirements.txt (line 2))\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->-r requirements.txt (line 2)) (9.3.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.11.1)\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (6.3.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: jsonpatch in /opt/conda/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.32)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.10/site-packages (from visdom>=0.1.8.8->-r requirements.txt (line 4)) (1.6.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (8.1.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (3.1.31)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (1.27.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (6.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 5)) (4.21.12)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->-r requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->-r requirements.txt (line 1)) (2.1.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch->visdom>=0.1.8.8->-r requirements.txt (line 4)) (2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 5)) (5.0.0)\n",
      "Building wheels for collected packages: visdom\n",
      "  Building wheel for visdom (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for visdom: filename=visdom-0.2.4-py3-none-any.whl size=1408196 sha256=a472992c1841ee056341ac62a66604e2f4e81b8299203d5178ecf3aa9a432114\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/42/29/49/5bed207bac4578e4d2c0c5fc0226bfd33a7e2953ea56356855\n",
      "Successfully built visdom\n",
      "Installing collected packages: dominate, visdom, torchvision\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0.dev20230705+cu118\n",
      "    Uninstalling torchvision-0.16.0.dev20230705+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.0.dev20230705+cu118\n",
      "Successfully installed dominate-2.8.0 torchvision-0.15.2 visdom-0.2.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8daqlgVhw29P"
   },
   "source": [
    "# Datasets\n",
    "\n",
    "Download one of the official datasets with:\n",
    "\n",
    "-   `bash ./datasets/download_pix2pix_dataset.sh [cityscapes, night2day, edges2handbags, edges2shoes, facades, maps]`\n",
    "\n",
    "Or use your own dataset by creating the appropriate folders and adding in the images. Follow the instructions [here](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/docs/datasets.md#pix2pix-datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrdOettJxaCc",
    "outputId": "c9b94448-a936-4b51-e399-aa11ad611b4a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_A] =  /home/jovyan/data/p2p_msrgb_ndvi/A\n",
      "[fold_B] =  /home/jovyan/data/p2p_msrgb_ndvi/B\n",
      "[fold_AB] =  /home/jovyan/data/p2p_msrgb_ndvi/AB\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  False\n",
      "split = train, use 750/750 images\n",
      "split = train, number of images = 750\n",
      "split = test, use 43/43 images\n",
      "split = test, number of images = 43\n"
     ]
    }
   ],
   "source": [
    "#Prepare the p2p dataset\n",
    "dataroot = \"/home/jovyan/data/p2p_msrgb_ndvi\"\n",
    "a = dataroot + \"/A\"\n",
    "b = dataroot + \"/B\"\n",
    "ab = dataroot + \"/AB\"\n",
    "!python datasets/combine_A_and_B.py --fold_A {a} --fold_B {b} --fold_AB {ab}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFw1kDQBx3LN"
   },
   "source": [
    "# Training\n",
    "\n",
    "-   `python train.py --dataroot ./datasets/facades --name facades_pix2pix --model pix2pix --direction BtoA`\n",
    "\n",
    "Change the `--dataroot` and `--name` to your own dataset's path and model's name. Use `--gpu_ids 0,1,..` to train on multiple GPUs and `--batch_size` to change the batch size. Add `--direction BtoA` if you want to train a model to transfrom from class B to A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "S41lg8QVCTUJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataroot = \"/home/jovyan/data/p2p_msrgb_ndvi/AB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0sp7TCT2x9dB",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "016dd877-4115-4b55-920f-dc5ac31544cf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "               batch_size: 32                            \t[default: 1]\n",
      "                    beta1: 0.5                           \n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "           continue_train: False                         \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /home/jovyan/data/p2p_msrgb_ndvi/AB\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "              display_env: main                          \n",
      "             display_freq: 400                           \n",
      "               display_id: -1                            \t[default: 1]\n",
      "            display_ncols: 4                             \n",
      "             display_port: 8097                          \n",
      "           display_server: http://localhost              \n",
      "          display_winsize: 256                           \n",
      "                    epoch: latest                        \n",
      "              epoch_count: 1                             \n",
      "                 gan_mode: vanilla                       \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: True                          \t[default: None]\n",
      "                lambda_L1: 100.0                         \n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \t[default: 286]\n",
      "                       lr: 0.0002                        \n",
      "           lr_decay_iters: 50                            \n",
      "                lr_policy: linear                        \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: cycle_gan]\n",
      "                 n_epochs: 50                            \t[default: 100]\n",
      "           n_epochs_decay: 50                            \t[default: 100]\n",
      "               n_layers_D: 3                             \n",
      "                     name: msrgb_ndvi_p2p                \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                  no_html: False                         \n",
      "                     norm: batch                         \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: train                         \n",
      "                pool_size: 0                             \n",
      "               preprocess: resize_and_crop               \n",
      "               print_freq: 100                           \n",
      "             save_by_iter: False                         \n",
      "          save_epoch_freq: 5                             \n",
      "         save_latest_freq: 5000                          \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "         update_html_freq: 1000                          \n",
      "                use_wandb: True                          \t[default: False]\n",
      "                  verbose: False                         \n",
      "       wandb_project_name: msrgb_ndvi                    \t[default: CycleGAN-and-pix2pix]\n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "The number of training images = 750\n",
      "initialize network with normal\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.410 M\n",
      "[Network D] Total number of parameters : 2.767 M\n",
      "-----------------------------------------------\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjurriandoornbos\u001b[0m (\u001b[33mjurrain-phd\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/jovyan/notebooks/pytorch-CycleGAN-and-pix2pix/wandb/run-20230913_072649-4oz0ln1g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmsrgb_ndvi_p2p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/jurrain-phd/msrgb_ndvi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/jurrain-phd/msrgb_ndvi/runs/4oz0ln1g\u001b[0m\n",
      "create web directory ./checkpoints/msrgb_ndvi_p2p/web...\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 1 / 100 \t Time Taken: 20 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 2, iters: 32, time: 0.030, data: 0.188) G_GAN: 0.743 G_L1: 9.972 D_real: 0.700 D_fake: 0.745 \n",
      "End of epoch 2 / 100 \t Time Taken: 8 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 3, iters: 64, time: 0.031, data: 0.004) G_GAN: 0.854 G_L1: 9.176 D_real: 0.811 D_fake: 0.811 \n",
      "End of epoch 3 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 4, iters: 96, time: 0.033, data: 0.006) G_GAN: 0.793 G_L1: 8.493 D_real: 0.645 D_fake: 0.679 \n",
      "End of epoch 4 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 5, iters: 128, time: 0.035, data: 0.014) G_GAN: 0.823 G_L1: 8.634 D_real: 0.613 D_fake: 0.669 \n",
      "saving the model at the end of epoch 5, iters 3840\n",
      "End of epoch 5 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 6, iters: 160, time: 0.034, data: 0.006) G_GAN: 0.977 G_L1: 8.249 D_real: 0.549 D_fake: 0.516 \n",
      "End of epoch 6 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 7, iters: 192, time: 0.033, data: 0.006) G_GAN: 1.297 G_L1: 8.160 D_real: 0.460 D_fake: 0.702 \n",
      "End of epoch 7 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 8, iters: 224, time: 0.034, data: 0.005) G_GAN: 1.483 G_L1: 8.885 D_real: 0.244 D_fake: 0.845 \n",
      "End of epoch 8 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 9, iters: 256, time: 0.034, data: 0.005) G_GAN: 0.929 G_L1: 10.421 D_real: 1.420 D_fake: 0.275 \n",
      "End of epoch 9 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 10, iters: 288, time: 0.034, data: 0.015) G_GAN: 1.519 G_L1: 9.030 D_real: 0.383 D_fake: 0.600 \n",
      "saving the model at the end of epoch 10, iters 7680\n",
      "End of epoch 10 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 11, iters: 320, time: 0.033, data: 0.004) G_GAN: 0.945 G_L1: 9.279 D_real: 0.508 D_fake: 0.789 \n",
      "End of epoch 11 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 12, iters: 352, time: 0.034, data: 0.005) G_GAN: 1.051 G_L1: 9.082 D_real: 0.515 D_fake: 0.574 \n",
      "End of epoch 12 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 13, iters: 384, time: 0.034, data: 0.005) G_GAN: 2.101 G_L1: 8.863 D_real: 0.227 D_fake: 0.861 \n",
      "End of epoch 13 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 14, iters: 416, time: 0.034, data: 0.005) G_GAN: 0.751 G_L1: 8.625 D_real: 0.932 D_fake: 0.391 \n",
      "End of epoch 14 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 15, iters: 448, time: 0.035, data: 0.005) G_GAN: 1.112 G_L1: 9.577 D_real: 0.632 D_fake: 0.455 \n",
      "saving the model at the end of epoch 15, iters 11520\n",
      "End of epoch 15 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 16, iters: 480, time: 0.035, data: 0.014) G_GAN: 0.629 G_L1: 9.269 D_real: 1.342 D_fake: 0.314 \n",
      "End of epoch 16 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 17, iters: 512, time: 0.037, data: 0.005) G_GAN: 1.370 G_L1: 9.141 D_real: 0.315 D_fake: 0.608 \n",
      "End of epoch 17 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 18, iters: 544, time: 0.038, data: 0.005) G_GAN: 1.113 G_L1: 9.243 D_real: 0.643 D_fake: 0.321 \n",
      "End of epoch 18 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 19, iters: 576, time: 0.039, data: 0.005) G_GAN: 0.822 G_L1: 9.423 D_real: 0.705 D_fake: 0.527 \n",
      "End of epoch 19 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 20, iters: 608, time: 0.037, data: 0.005) G_GAN: 0.845 G_L1: 9.258 D_real: 1.111 D_fake: 0.264 \n",
      "saving the model at the end of epoch 20, iters 15360\n",
      "End of epoch 20 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 21, iters: 640, time: 0.037, data: 0.005) G_GAN: 0.811 G_L1: 9.467 D_real: 0.954 D_fake: 0.321 \n",
      "End of epoch 21 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 22, iters: 672, time: 0.036, data: 0.005) G_GAN: 1.114 G_L1: 9.100 D_real: 0.467 D_fake: 0.563 \n",
      "End of epoch 22 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 23, iters: 704, time: 0.036, data: 0.005) G_GAN: 0.756 G_L1: 9.619 D_real: 0.747 D_fake: 0.525 \n",
      "End of epoch 23 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 24, iters: 736, time: 0.038, data: 0.005) G_GAN: 1.660 G_L1: 9.008 D_real: 0.323 D_fake: 0.940 \n",
      "End of epoch 24 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 25, iters: 768, time: 0.030, data: 0.005) G_GAN: 1.066 G_L1: 8.882 D_real: 0.607 D_fake: 0.807 \n",
      "saving the model at the end of epoch 25, iters 19200\n",
      "End of epoch 25 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "End of epoch 26 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 27, iters: 32, time: 0.025, data: 0.239) G_GAN: 0.745 G_L1: 8.945 D_real: 0.681 D_fake: 0.419 \n",
      "saving the latest model (epoch 27, total_iters 20000)\n",
      "End of epoch 27 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 28, iters: 64, time: 0.036, data: 0.005) G_GAN: 0.798 G_L1: 9.126 D_real: 0.577 D_fake: 0.581 \n",
      "End of epoch 28 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 29, iters: 96, time: 0.040, data: 0.004) G_GAN: 1.061 G_L1: 8.545 D_real: 0.486 D_fake: 0.594 \n",
      "End of epoch 29 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 30, iters: 128, time: 0.037, data: 0.005) G_GAN: 0.868 G_L1: 8.836 D_real: 0.563 D_fake: 0.612 \n",
      "saving the model at the end of epoch 30, iters 23040\n",
      "End of epoch 30 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 31, iters: 160, time: 0.036, data: 0.015) G_GAN: 0.953 G_L1: 8.730 D_real: 0.533 D_fake: 0.516 \n",
      "End of epoch 31 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 32, iters: 192, time: 0.036, data: 0.004) G_GAN: 0.657 G_L1: 9.211 D_real: 0.918 D_fake: 0.471 \n",
      "End of epoch 32 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 33, iters: 224, time: 0.038, data: 0.004) G_GAN: 0.933 G_L1: 8.806 D_real: 0.595 D_fake: 0.492 \n",
      "End of epoch 33 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 34, iters: 256, time: 0.038, data: 0.007) G_GAN: 0.940 G_L1: 9.043 D_real: 0.668 D_fake: 0.669 \n",
      "End of epoch 34 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 35, iters: 288, time: 0.037, data: 0.005) G_GAN: 0.769 G_L1: 8.532 D_real: 0.599 D_fake: 0.703 \n",
      "saving the model at the end of epoch 35, iters 26880\n",
      "End of epoch 35 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 36, iters: 320, time: 0.037, data: 0.004) G_GAN: 0.826 G_L1: 8.672 D_real: 0.642 D_fake: 0.691 \n",
      "End of epoch 36 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 37, iters: 352, time: 0.037, data: 0.005) G_GAN: 1.407 G_L1: 8.678 D_real: 0.403 D_fake: 0.901 \n",
      "End of epoch 37 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 38, iters: 384, time: 0.038, data: 0.005) G_GAN: 0.963 G_L1: 8.547 D_real: 0.642 D_fake: 0.509 \n",
      "End of epoch 38 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 39, iters: 416, time: 0.038, data: 0.005) G_GAN: 0.881 G_L1: 8.067 D_real: 0.578 D_fake: 0.566 \n",
      "End of epoch 39 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 40, iters: 448, time: 0.038, data: 0.013) G_GAN: 1.076 G_L1: 7.223 D_real: 0.412 D_fake: 0.730 \n",
      "saving the model at the end of epoch 40, iters 30720\n",
      "End of epoch 40 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 41, iters: 480, time: 0.037, data: 0.005) G_GAN: 0.843 G_L1: 8.076 D_real: 0.656 D_fake: 0.728 \n",
      "End of epoch 41 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 42, iters: 512, time: 0.035, data: 0.005) G_GAN: 0.841 G_L1: 8.047 D_real: 0.707 D_fake: 0.564 \n",
      "End of epoch 42 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 43, iters: 544, time: 0.037, data: 0.005) G_GAN: 0.759 G_L1: 7.998 D_real: 0.719 D_fake: 0.447 \n",
      "End of epoch 43 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 44, iters: 576, time: 0.036, data: 0.005) G_GAN: 0.877 G_L1: 8.257 D_real: 0.601 D_fake: 0.555 \n",
      "End of epoch 44 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 45, iters: 608, time: 0.038, data: 0.005) G_GAN: 0.763 G_L1: 7.659 D_real: 0.727 D_fake: 0.591 \n",
      "saving the model at the end of epoch 45, iters 34560\n",
      "End of epoch 45 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 46, iters: 640, time: 0.039, data: 0.005) G_GAN: 1.076 G_L1: 8.238 D_real: 0.503 D_fake: 0.714 \n",
      "End of epoch 46 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 47, iters: 672, time: 0.039, data: 0.005) G_GAN: 0.777 G_L1: 7.726 D_real: 0.653 D_fake: 0.755 \n",
      "End of epoch 47 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 48, iters: 704, time: 0.040, data: 0.005) G_GAN: 1.014 G_L1: 7.879 D_real: 0.473 D_fake: 0.854 \n",
      "End of epoch 48 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0002000\n",
      "(epoch: 49, iters: 736, time: 0.037, data: 0.005) G_GAN: 0.841 G_L1: 7.903 D_real: 0.650 D_fake: 0.555 \n",
      "End of epoch 49 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0002000 -> 0.0001961\n",
      "(epoch: 50, iters: 768, time: 0.032, data: 0.005) G_GAN: 1.021 G_L1: 8.182 D_real: 0.446 D_fake: 0.665 \n",
      "saving the model at the end of epoch 50, iters 38400\n",
      "End of epoch 50 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0001961 -> 0.0001922\n",
      "End of epoch 51 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0001922 -> 0.0001882\n",
      "(epoch: 52, iters: 32, time: 0.025, data: 0.231) G_GAN: 0.717 G_L1: 7.378 D_real: 0.760 D_fake: 0.565 \n",
      "End of epoch 52 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001882 -> 0.0001843\n",
      "(epoch: 53, iters: 64, time: 0.038, data: 0.005) G_GAN: 0.683 G_L1: 7.389 D_real: 0.790 D_fake: 0.537 \n",
      "saving the latest model (epoch 53, total_iters 40000)\n",
      "End of epoch 53 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001843 -> 0.0001804\n",
      "(epoch: 54, iters: 96, time: 0.047, data: 0.005) G_GAN: 0.832 G_L1: 7.141 D_real: 0.841 D_fake: 0.499 \n",
      "End of epoch 54 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001804 -> 0.0001765\n",
      "(epoch: 55, iters: 128, time: 0.038, data: 0.005) G_GAN: 1.039 G_L1: 7.510 D_real: 0.479 D_fake: 0.799 \n",
      "saving the model at the end of epoch 55, iters 42240\n",
      "End of epoch 55 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0001765 -> 0.0001725\n",
      "(epoch: 56, iters: 160, time: 0.036, data: 0.014) G_GAN: 1.196 G_L1: 8.559 D_real: 0.368 D_fake: 0.725 \n",
      "End of epoch 56 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0001725 -> 0.0001686\n",
      "(epoch: 57, iters: 192, time: 0.037, data: 0.004) G_GAN: 0.583 G_L1: 7.856 D_real: 0.846 D_fake: 0.466 \n",
      "End of epoch 57 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0001686 -> 0.0001647\n",
      "(epoch: 58, iters: 224, time: 0.037, data: 0.005) G_GAN: 1.019 G_L1: 7.475 D_real: 0.482 D_fake: 0.683 \n",
      "End of epoch 58 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0001647 -> 0.0001608\n",
      "(epoch: 59, iters: 256, time: 0.039, data: 0.004) G_GAN: 1.114 G_L1: 7.176 D_real: 0.421 D_fake: 0.919 \n",
      "End of epoch 59 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001608 -> 0.0001569\n",
      "(epoch: 60, iters: 288, time: 0.040, data: 0.005) G_GAN: 0.746 G_L1: 7.533 D_real: 1.034 D_fake: 0.378 \n",
      "saving the model at the end of epoch 60, iters 46080\n",
      "End of epoch 60 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0001569 -> 0.0001529\n",
      "(epoch: 61, iters: 320, time: 0.039, data: 0.013) G_GAN: 0.835 G_L1: 7.413 D_real: 0.646 D_fake: 0.568 \n",
      "End of epoch 61 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001529 -> 0.0001490\n",
      "(epoch: 62, iters: 352, time: 0.036, data: 0.005) G_GAN: 0.663 G_L1: 7.526 D_real: 0.813 D_fake: 0.450 \n",
      "End of epoch 62 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001490 -> 0.0001451\n",
      "(epoch: 63, iters: 384, time: 0.041, data: 0.005) G_GAN: 0.665 G_L1: 7.542 D_real: 0.909 D_fake: 0.560 \n",
      "End of epoch 63 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001451 -> 0.0001412\n",
      "(epoch: 64, iters: 416, time: 0.036, data: 0.005) G_GAN: 0.639 G_L1: 7.521 D_real: 0.718 D_fake: 0.683 \n",
      "End of epoch 64 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001412 -> 0.0001373\n",
      "(epoch: 65, iters: 448, time: 0.037, data: 0.005) G_GAN: 1.076 G_L1: 6.976 D_real: 0.482 D_fake: 0.858 \n",
      "saving the model at the end of epoch 65, iters 49920\n",
      "End of epoch 65 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0001373 -> 0.0001333\n",
      "(epoch: 66, iters: 480, time: 0.039, data: 0.005) G_GAN: 0.867 G_L1: 7.356 D_real: 0.582 D_fake: 0.633 \n",
      "End of epoch 66 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001333 -> 0.0001294\n",
      "(epoch: 67, iters: 512, time: 0.040, data: 0.005) G_GAN: 0.740 G_L1: 6.884 D_real: 0.761 D_fake: 0.666 \n",
      "End of epoch 67 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001294 -> 0.0001255\n",
      "(epoch: 68, iters: 544, time: 0.039, data: 0.005) G_GAN: 0.701 G_L1: 6.881 D_real: 0.819 D_fake: 0.588 \n",
      "End of epoch 68 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001255 -> 0.0001216\n",
      "(epoch: 69, iters: 576, time: 0.039, data: 0.005) G_GAN: 0.884 G_L1: 6.866 D_real: 0.483 D_fake: 0.815 \n",
      "End of epoch 69 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001216 -> 0.0001176\n",
      "(epoch: 70, iters: 608, time: 0.037, data: 0.005) G_GAN: 0.705 G_L1: 6.668 D_real: 0.729 D_fake: 0.665 \n",
      "saving the model at the end of epoch 70, iters 53760\n",
      "End of epoch 70 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0001176 -> 0.0001137\n",
      "(epoch: 71, iters: 640, time: 0.040, data: 0.005) G_GAN: 0.846 G_L1: 6.902 D_real: 0.568 D_fake: 0.716 \n",
      "End of epoch 71 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001137 -> 0.0001098\n",
      "(epoch: 72, iters: 672, time: 0.041, data: 0.005) G_GAN: 0.688 G_L1: 7.102 D_real: 0.682 D_fake: 0.609 \n",
      "End of epoch 72 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0001098 -> 0.0001059\n",
      "(epoch: 73, iters: 704, time: 0.037, data: 0.005) G_GAN: 0.746 G_L1: 7.140 D_real: 0.661 D_fake: 0.624 \n",
      "End of epoch 73 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0001059 -> 0.0001020\n",
      "(epoch: 74, iters: 736, time: 0.038, data: 0.005) G_GAN: 0.717 G_L1: 6.842 D_real: 0.656 D_fake: 0.633 \n",
      "End of epoch 74 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0001020 -> 0.0000980\n",
      "(epoch: 75, iters: 768, time: 0.031, data: 0.005) G_GAN: 0.937 G_L1: 7.333 D_real: 0.448 D_fake: 0.871 \n",
      "saving the model at the end of epoch 75, iters 57600\n",
      "End of epoch 75 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0000980 -> 0.0000941\n",
      "End of epoch 76 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000941 -> 0.0000902\n",
      "(epoch: 77, iters: 32, time: 0.026, data: 0.249) G_GAN: 0.775 G_L1: 6.668 D_real: 0.669 D_fake: 0.618 \n",
      "End of epoch 77 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000902 -> 0.0000863\n",
      "(epoch: 78, iters: 64, time: 0.038, data: 0.005) G_GAN: 0.779 G_L1: 6.780 D_real: 0.523 D_fake: 0.780 \n",
      "End of epoch 78 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000863 -> 0.0000824\n",
      "(epoch: 79, iters: 96, time: 0.037, data: 0.004) G_GAN: 0.774 G_L1: 6.674 D_real: 0.580 D_fake: 0.647 \n",
      "saving the latest model (epoch 79, total_iters 60000)\n",
      "End of epoch 79 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0000824 -> 0.0000784\n",
      "(epoch: 80, iters: 128, time: 0.040, data: 0.006) G_GAN: 0.764 G_L1: 7.026 D_real: 0.648 D_fake: 0.615 \n",
      "saving the model at the end of epoch 80, iters 61440\n",
      "End of epoch 80 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0000784 -> 0.0000745\n",
      "(epoch: 81, iters: 160, time: 0.042, data: 0.005) G_GAN: 0.747 G_L1: 6.775 D_real: 0.686 D_fake: 0.558 \n",
      "End of epoch 81 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000745 -> 0.0000706\n",
      "(epoch: 82, iters: 192, time: 0.039, data: 0.004) G_GAN: 0.721 G_L1: 7.064 D_real: 0.661 D_fake: 0.604 \n",
      "End of epoch 82 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0000706 -> 0.0000667\n",
      "(epoch: 83, iters: 224, time: 0.038, data: 0.004) G_GAN: 0.738 G_L1: 6.454 D_real: 0.538 D_fake: 0.869 \n",
      "End of epoch 83 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000667 -> 0.0000627\n",
      "(epoch: 84, iters: 256, time: 0.038, data: 0.005) G_GAN: 0.785 G_L1: 6.691 D_real: 0.580 D_fake: 0.692 \n",
      "End of epoch 84 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000627 -> 0.0000588\n",
      "(epoch: 85, iters: 288, time: 0.038, data: 0.006) G_GAN: 0.762 G_L1: 6.553 D_real: 0.607 D_fake: 0.767 \n",
      "saving the model at the end of epoch 85, iters 65280\n",
      "End of epoch 85 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0000588 -> 0.0000549\n",
      "(epoch: 86, iters: 320, time: 0.036, data: 0.005) G_GAN: 0.761 G_L1: 6.865 D_real: 0.698 D_fake: 0.587 \n",
      "End of epoch 86 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000549 -> 0.0000510\n",
      "(epoch: 87, iters: 352, time: 0.036, data: 0.005) G_GAN: 0.619 G_L1: 6.538 D_real: 0.735 D_fake: 0.716 \n",
      "End of epoch 87 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000510 -> 0.0000471\n",
      "(epoch: 88, iters: 384, time: 0.039, data: 0.005) G_GAN: 0.795 G_L1: 6.478 D_real: 0.572 D_fake: 0.679 \n",
      "End of epoch 88 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000471 -> 0.0000431\n",
      "(epoch: 89, iters: 416, time: 0.038, data: 0.006) G_GAN: 0.698 G_L1: 6.630 D_real: 0.677 D_fake: 0.714 \n",
      "End of epoch 89 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000431 -> 0.0000392\n",
      "(epoch: 90, iters: 448, time: 0.038, data: 0.005) G_GAN: 0.750 G_L1: 6.979 D_real: 0.773 D_fake: 0.608 \n",
      "saving the model at the end of epoch 90, iters 69120\n",
      "End of epoch 90 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0000392 -> 0.0000353\n",
      "(epoch: 91, iters: 480, time: 0.042, data: 0.013) G_GAN: 0.776 G_L1: 6.460 D_real: 0.617 D_fake: 0.631 \n",
      "End of epoch 91 / 100 \t Time Taken: 10 sec\n",
      "learning rate 0.0000353 -> 0.0000314\n",
      "(epoch: 92, iters: 512, time: 0.039, data: 0.005) G_GAN: 0.775 G_L1: 6.730 D_real: 0.543 D_fake: 0.710 \n",
      "End of epoch 92 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000314 -> 0.0000275\n",
      "(epoch: 93, iters: 544, time: 0.038, data: 0.005) G_GAN: 0.796 G_L1: 6.445 D_real: 0.714 D_fake: 0.576 \n",
      "End of epoch 93 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000275 -> 0.0000235\n",
      "(epoch: 94, iters: 576, time: 0.039, data: 0.005) G_GAN: 0.744 G_L1: 6.805 D_real: 0.682 D_fake: 0.650 \n",
      "End of epoch 94 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000235 -> 0.0000196\n",
      "(epoch: 95, iters: 608, time: 0.037, data: 0.005) G_GAN: 0.857 G_L1: 6.714 D_real: 0.606 D_fake: 0.570 \n",
      "saving the model at the end of epoch 95, iters 72960\n",
      "End of epoch 95 / 100 \t Time Taken: 11 sec\n",
      "learning rate 0.0000196 -> 0.0000157\n",
      "(epoch: 96, iters: 640, time: 0.041, data: 0.005) G_GAN: 0.821 G_L1: 6.824 D_real: 0.603 D_fake: 0.604 \n",
      "End of epoch 96 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000157 -> 0.0000118\n",
      "(epoch: 97, iters: 672, time: 0.039, data: 0.005) G_GAN: 0.785 G_L1: 6.611 D_real: 0.630 D_fake: 0.613 \n",
      "End of epoch 97 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000118 -> 0.0000078\n",
      "(epoch: 98, iters: 704, time: 0.038, data: 0.005) G_GAN: 0.750 G_L1: 6.506 D_real: 0.644 D_fake: 0.656 \n",
      "End of epoch 98 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000078 -> 0.0000039\n",
      "(epoch: 99, iters: 736, time: 0.038, data: 0.005) G_GAN: 0.686 G_L1: 6.231 D_real: 0.680 D_fake: 0.722 \n",
      "End of epoch 99 / 100 \t Time Taken: 9 sec\n",
      "learning rate 0.0000039 -> 0.0000000\n",
      "(epoch: 100, iters: 768, time: 0.032, data: 0.005) G_GAN: 0.634 G_L1: 6.267 D_real: 0.677 D_fake: 0.776 \n",
      "saving the model at the end of epoch 100, iters 76800\n",
      "End of epoch 100 / 100 \t Time Taken: 11 sec\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run \u001b[33mmsrgb_ndvi_p2p\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/jurrain-phd/msrgb_ndvi/runs/4oz0ln1g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 384 media file(s), 386 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230913_072649-4oz0ln1g/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --dataroot {dataroot} \\\n",
    "  --name msrgb_ndvi_p2p \\\n",
    "  --model pix2pix \\\n",
    "  --output_nc 1 \\\n",
    "  --direction AtoB \\\n",
    "  --display_id -1 \\\n",
    "  --batch_size 32 \\\n",
    "  --load_size 256 \\\n",
    "  --save_epoch_freq 5 \\\n",
    "  --n_epochs 50 \\\n",
    "  --n_epochs_decay 50 \\\n",
    "  --dataset_mode aligned \\\n",
    "  --use_wandb \\\n",
    "  --wandb_project_name msrgb_ndvi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mey7o6j-0368",
    "outputId": "e288088f-7803-4b73-8453-6a197d407fac",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msrgb_ndvi_p2p\n"
     ]
    }
   ],
   "source": [
    "!ls checkpoints/\n",
    "dataroot = \"/home/jovyan/data/p2p_msrgb_ndvi/AB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "uCsKkEq0yGh0",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0d938006-7b05-4240-fd7e-d3960a898c9b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- Options ---------------\n",
      "             aspect_ratio: 1.0                           \n",
      "               batch_size: 32                            \t[default: 1]\n",
      "          checkpoints_dir: ./checkpoints                 \n",
      "                crop_size: 256                           \n",
      "                 dataroot: /home/jovyan/data/p2p_msrgb_ndvi/AB\t[default: None]\n",
      "             dataset_mode: aligned                       \n",
      "                direction: AtoB                          \n",
      "          display_winsize: 256                           \n",
      "                    epoch: 100                           \t[default: latest]\n",
      "                     eval: False                         \n",
      "                  gpu_ids: 0                             \n",
      "                init_gain: 0.02                          \n",
      "                init_type: normal                        \n",
      "                 input_nc: 3                             \n",
      "                  isTrain: False                         \t[default: None]\n",
      "                load_iter: 0                             \t[default: 0]\n",
      "                load_size: 256                           \n",
      "         max_dataset_size: inf                           \n",
      "                    model: pix2pix                       \t[default: test]\n",
      "               n_layers_D: 3                             \n",
      "                     name: msrgb_ndvi_p2p                \t[default: experiment_name]\n",
      "                      ndf: 64                            \n",
      "                     netD: basic                         \n",
      "                     netG: unet_256                      \n",
      "                      ngf: 64                            \n",
      "               no_dropout: False                         \n",
      "                  no_flip: False                         \n",
      "                     norm: batch                         \n",
      "                 num_test: 50                            \n",
      "              num_threads: 4                             \n",
      "                output_nc: 1                             \t[default: 3]\n",
      "                    phase: test                          \n",
      "               preprocess: resize_and_crop               \n",
      "              results_dir: ./results/                    \n",
      "           serial_batches: False                         \n",
      "                   suffix:                               \n",
      "                use_wandb: False                         \n",
      "                  verbose: False                         \n",
      "       wandb_project_name: CycleGAN-and-pix2pix          \n",
      "----------------- End -------------------\n",
      "dataset [AlignedDataset] was created\n",
      "initialize network with normal\n",
      "model [Pix2PixModel] was created\n",
      "loading the model from ./checkpoints/msrgb_ndvi_p2p/100_net_G.pth\n",
      "---------- Networks initialized -------------\n",
      "[Network G] Total number of parameters : 54.410 M\n",
      "-----------------------------------------------\n",
      "creating web directory ./results/msrgb_ndvi_p2p/test_100\n",
      "processing (0000)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000000.jpg']\n",
      "processing (0005)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000005.jpg']\n",
      "processing (0010)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000010.jpg']\n",
      "processing (0015)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000015.jpg']\n",
      "processing (0020)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000020.jpg']\n",
      "processing (0025)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000025.jpg']\n",
      "processing (0030)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000030.jpg']\n",
      "processing (0035)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000035.jpg']\n",
      "processing (0040)-th image... ['/home/jovyan/data/p2p_msrgb_ndvi/AB/test/000040.jpg']\n"
     ]
    }
   ],
   "source": [
    "!python test.py --dataroot {dataroot} \\\n",
    "  --name msrgb_ndvi_p2p \\\n",
    "  --model pix2pix \\\n",
    "  --output_nc 1 \\\n",
    "  --direction AtoB \\\n",
    "  --batch_size 32 \\\n",
    "  --load_size 256 \\\n",
    "  --dataset_mode aligned \\\n",
    "  --epoch 100 \\\n",
    "  --phase test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-3.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m74"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
